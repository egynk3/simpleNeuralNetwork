{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVN6vlYs6z+nxe84+aL8gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/egynk3/simpleNeuralNetwork/blob/main/SimpleNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1juTw2lBLIub",
        "outputId": "a2e05e08-033a-4297-fa46-92233c112a8a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-39773322.py, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-39773322.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    \"\"\"Read and preprocess data from the specified root path.\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "#importing relevant libs\n",
        "import numpy as np               # Numerical operations\n",
        "import pandas as pd              # Data handling (e.g., read CSV files)\n",
        "from sklearn.model_selection import train_test_split   # Split data into train/test\n",
        "from sklearn.preprocessing import StandardScaler       # Normalize features\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "#evaluation and vizualization\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "#importing data\n",
        "url='https://github.com/egynk3/simpleNeuralNetwork/raw/main/Data/AllData.xlsx'\n",
        "df = pd.read_excel(url)\n",
        "\n",
        "#normalize data:\n",
        "#df mean=mean of each column in dataframe\n",
        "#df-df.mean= subtract column mean from each value in column\n",
        "#data now centered around zero\n",
        "#df.std std of ech column as a series\n",
        "#after, mean=zero and standard deviation of each col=1\n",
        "#not normalizing outputs, axis=1 =cols\n",
        "#splitting into features and targets\n",
        "\n",
        "features = df.drop('h', axis=1)\n",
        "target = df['h']\n",
        "features_norm = (features - features.mean()) / features.std()\n",
        "X=features_norm.values\n",
        "y=target.values\n",
        "#######################################################################\n",
        "#splitting dataset into training set and temporary set(for val and test):\n",
        "#.3=30% data goes into temp, 70% to train\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=33)\n",
        "#splitting temporary into val and test set, 50/50 split\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=33)\n",
        "\n",
        "########################################################\n",
        "#scale inputs and outputs\n",
        "#creation of scalar objects\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "#mean and std of each column, transform applies to all values\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "#fit not called to avoid data leakage, scaled using training data mean and std\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "#reshaping to a 2d array\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
        "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1))\n",
        "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "#currently all numpy arrays\n",
        "########################################################\n",
        "\n",
        "\n",
        "########################################################\n",
        "##define network architecture\n",
        "class outputHeight(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(outputHeight, self).__init__()\n",
        "        #layer definiton\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),#input to hidden layer\n",
        "            nn.ReLU(), #activation\n",
        "            nn.Linear(64,32), #hidden to hidden\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32,1) #hidden to output\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "#OPTIONAL         drop out + batch normalization for training stability\n",
        "\n",
        "#define loss funciton\n",
        "lossFunc = nn.MSELoss() #regression\n",
        "#define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#optional                             metric tracker r^2\n",
        "#convertin numpy arrays to pytorch tensors\n",
        "x_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
        "x_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val_scaled, dtype=torch.float32)\n",
        "#dataloader objects for batching\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "#feed training data into model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()#model in training mode\n",
        "    train_loss= 0.0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        optimizer.zero_grad() #clear prev gradients\n",
        "        outputs = model(batch_x) #forward pass\n",
        "        loss = lossFunc(outputs, batch_y) #compute loss\n",
        "        loss.backward() #packpropagation\n",
        "        optimizer.step() #updating weights\n",
        "        train_loss += loss.item()*batch_x.size(0) #accumulating loss\n",
        "    train_loss /= len(train_loader.dataset) #average loss over epoch\n",
        "    #validation loop, monitering overfitting\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad(): #no gradients during validation\n",
        "        val_outputs = model(x_val_tensor)\n",
        "        val_loss = lossFunc(val_outputs, y_val_tensor).item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "    if epoch == 0:\n",
        "      best_val_loss = val_loss\n",
        "      torch.save(model.state_dict(), 'best_model.pth')\n",
        "    elif val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      torch.save(model.state_dict(), 'best_model.pth') #save best model\n",
        "#load best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "#convert test numpy arrays to tensors\n",
        "x_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
        "#run predictions on test set\n",
        "with torch.no_grad():\n",
        "  y_pred_test_scaled = model(x_test_tensor)\n",
        "  #INVERSE SCALING\n",
        "  y_pred_test = scaler_y.inverse_transform(y_pred_test_scaled.numpy())\n",
        "  y_true_test = scaler_y.inverse_transform(y_test_scaled)\n",
        "  #evaluate performance\n",
        "  mse = mean_squared_error(y_true_test, y_pred_test)\n",
        "  mae = mean_absolute_error(y_true_test, y_pred_test)\n",
        "  r2 = r2_score(y_true_test, y_pred_test)\n",
        "  print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
        "  #visualisation\n",
        "  plt.scatter(y_true_test, y_pred_test, alpha=0.6)\n",
        "  plt.xlabel('True Height Output')\n",
        "  plt.ylabel('Predicted Height')\n",
        "  plt.title('Test vs True Height')\n",
        "  plt.plot([y_true_test.min(), y_true_test.max()],\n",
        "           [y_true_test.min(), y_true_test.max()],\n",
        "           'r--')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#########################################################\n",
        "#save trained model weights\n",
        "#function that takes new values and returns predicted\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXFi0lgK0j4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}